### **Distance Classification**
Distance classification is a method used to group or categorize data points based on how far they are from one another in a defined space. The idea is that similar data points are closer together, and different ones are farther apart. 

For example:
- In a 2D plane, if we have a point $A$ and other points around it, we can classify these points into groups (or labels) by measuring their distance to $A$.

---

### **Core Idea**
The core idea of distance-based classification is to compare the distance of a given data point (input) to predefined reference points (e.g., known categories or training samples). Based on these distances, we assign the point to a specific group.

#### **General Formula for Distance**
The formula to calculate the distance between two points $P(x_1, y_1)$ and $Q(x_2, y_2)$ depends on the type of distance metric used. 

In general, for two points in $n$-dimensional space $P(x_1, x_2, \dots, x_n)$ and $Q(y_1, y_2, \dots, y_n)$, the **generalized distance formula** is:

$$
D(P, Q) = \left( \sum_{i=1}^n |x_i - y_i|^p \right)^{1/p}
$$

- $p$ determines the type of distance (e.g., $p = 2$ for Euclidean, $p = 1$ for Manhattan).

---

### **Types of Distances**

#### **1. Euclidean Distance**
The straight-line distance between two points in space.
- **Formula:**
$$
D = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}
$$
- **Intuition:** Imagine measuring the shortest path between two points with a ruler.
- **Use-Case:** Works well when directions and true physical distances matter (e.g., spatial problems, clustering).

#### **2. Manhattan Distance (L1 Norm)**
The sum of absolute differences of their coordinates.
- **Formula:**
$$
D = \sum_{i=1}^n |x_i - y_i|
$$
- **Intuition:** Think of walking on a grid-like city map where you can only move horizontally or vertically.
- **Use-Case:** Useful for grid-based systems like navigation in cities or for high-dimensional spaces where diagonal distance is less relevant.

#### **3. Chebyshev Distance (Lâˆž Norm)**
The maximum absolute difference between coordinates.
- **Formula:**
$$
D = \max_{i=1}^n |x_i - y_i|
$$
- **Intuition:** Measures the longest one-step movement required to reach the point.
- **Use-Case:** Useful in games like chess, where only the farthest movement matters (e.g., king moves).

#### **Comparison**
| Distance| Path Type| Key Feature | Example Use-Case|
|-------------|------------------------|--------------------------------|---------------------------------------|
| Euclidean | Straight-line path | Most accurate for spatial data| Clustering or real-world coordinates|
| Manhattan | Grid or stepwise path| Handles grid-based systems| City navigation, high-dimensional data|
| Chebyshev | Longest single move| Max coordinate difference | Chess moves, warehouse logistics|

---

### **Classifiers**

#### **1. Minimum Distance Classifier**
Assigns a point to the class with the closest centroid (average position of the class).
- **How It Works:** Calculate the distance from the input point to all class centroids and pick the smallest one.
- **Use-Case:** Simple classification with well-separated classes (e.g., grouping customers based on average behavior).

#### **2. Box Classifier**
Divides the space into boxes (regions) and assigns all points inside each box to a specific class.
- **How It Works:** Define boundaries for each class in the form of a box.
- **Use-Case:** Fast classification when boundaries are clear and fixed (e.g., age and income brackets for marketing).

#### **3. k-Nearest Neighbors (KNN)**
Assigns a point to the class of its $k$ nearest neighbors.
- **How It Works:** 
1. Choose $k$ (e.g., 3 or 5).
2. Find the $k$-nearest points to the input.
3. Assign the majority class among these $k$ neighbors.
- **Use-Case:** Versatile; used when boundaries are complex or unknown (e.g., image recognition, anomaly detection).

#### **Comparison**
| Classifier| Method | Pros | Cons| Example Use-Case|
|---------------------|--------------------------------|--------------------------------------|---------------------------------------|---------------------------------------|
| Minimum Distance| Closest centroid| Simple and fast | Struggles with overlapping data | Customer segmentation |
| Box Classifier| Box-based boundaries| Quick for fixed regions | Rigid; doesn't handle overlap well| Age/income groupings|
| K-Nearest Neighbors | Based on nearest neighbors| Flexible, handles complex data| Slow for large datasets | Image or voice classification |
